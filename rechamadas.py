import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import io

warnings.filterwarnings('ignore')

# --- CONFIGURAÃ‡Ã•ES GLOBAIS ---
VALOR_LIGACAO = 7.56
MIN_LIGACOES_GRAF = 2

# --- 1. FUNÃ‡Ã•ES AUXILIARES ---
def converter_duracao_para_segundos(duracao_str):
    """Converte string de duraÃ§Ã£o (mm:ss ou hh:mm:ss) para segundos."""
    try:
        duracao_str = str(duracao_str).strip()
        if ':' in duracao_str:
            partes = list(map(int, duracao_str.split(':')))
            if len(partes) == 2:  # mm:ss
                return partes[0] * 60 + partes[1]
            elif len(partes) == 3:  # hh:mm:ss
                return partes[0] * 3600 + partes[1] * 60 + partes[2]
        else:
            return int(float(duracao_str))
    except ValueError:
        return 0

def detectar_coluna_sugerida(df, tipo='datetime'):
    """
    Detecta e sugere colunas baseado no tipo solicitado.
    tipo: 'datetime', 'telefone', 'duracao'
    """
    sugestoes = []

    if tipo == 'datetime':
        palavras_chave = ['data', 'datetime', 'timestamp', 'hora', 'time', 'date']
        for col in df.columns:
            col_lower = col.lower()
            if any(palavra in col_lower for palavra in palavras_chave):
                sugestoes.append(col)

    elif tipo == 'telefone':
        palavras_chave = ['telefone', 'phone', 'numero', 'fone', 'tel', 'ani', 'cliente', 'customer']
        for col in df.columns:
            col_lower = col.lower()
            if any(palavra in col_lower for palavra in palavras_chave):
                sugestoes.append(col)

    elif tipo == 'duracao':
        palavras_chave = ['duracao', 'duraÃ§Ã£o', 'duration', 'tempo', 'time']
        for col in df.columns:
            col_lower = col.lower()
            if any(palavra in col_lower for palavra in palavras_chave):
                sugestoes.append(col)

    return sugestoes[0] if sugestoes else None

# --- 2. CARREGAMENTO INICIAL DOS DADOS ---
@st.cache_data(show_spinner="Carregando arquivo...")
def carregar_arquivo_inicial(uploaded_file):
    """
    Carrega o arquivo e retorna DataFrame bruto para seleÃ§Ã£o de colunas.
    """
    if uploaded_file is None:
        return None, "Nenhum arquivo carregado."

    file_details = {
        "filename": uploaded_file.name, 
        "filetype": uploaded_file.type, 
        "filesize": uploaded_file.size
    }

    st.write(f"ğŸ“– Arquivo: **{file_details['filename']}** ({file_details['filesize'] / 1024:.2f} KB)")

    dfs = []
    file_extension = uploaded_file.name.split('.')[-1].lower()

    try:
        if file_extension == 'csv':
            uploaded_file_content = uploaded_file.getvalue()

            for encoding in ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']:
                for sep in [',', ';', '\t']:
                    try:
                        df_temp = pd.read_csv(
                            io.StringIO(uploaded_file_content.decode(encoding)), 
                            sep=sep
                        )
                        if not df_temp.empty and len(df_temp.columns) > 1:
                            st.success(f"âœ… CSV carregado com encoding: {encoding}, separador: '{sep}'")
                            dfs.append(df_temp)
                            break
                    except Exception:
                        continue
                if dfs:
                    break

        elif file_extension in ['xlsx', 'xls']:
            uploaded_file.seek(0)
            excel_file = pd.ExcelFile(uploaded_file)
            sheet_names = excel_file.sheet_names
            st.info(f"ğŸ“Š Excel com {len(sheet_names)} aba(s): {', '.join(sheet_names)}")

            for sheet_name in sheet_names:
                df_temp = pd.read_excel(excel_file, sheet_name=sheet_name)
                if not df_temp.empty and len(df_temp.columns) > 1:
                    dfs.append(df_temp)
                    st.success(f"âœ… Aba '{sheet_name}' carregada")

        if not dfs:
            return None, "Nenhum dado vÃ¡lido encontrado no arquivo."

        df_completo = pd.concat(dfs, ignore_index=True)
        df_completo = df_completo.loc[:, ~df_completo.columns.str.contains('^Unnamed', na=False)]

        st.success(f"âœ… Total de registros carregados: **{len(df_completo):,}**")
        return df_completo, None

    except Exception as e:
        return None, f"Erro ao carregar arquivo: {str(e)}"

# --- 3. PROCESSAMENTO DOS DADOS COM COLUNAS SELECIONADAS ---
@st.cache_data(show_spinner="Processando dados...")
def processar_dados(df_bruto, col_datetime, col_cliente, col_duracao=None):
    """
    Processa o DataFrame com as colunas selecionadas pelo usuÃ¡rio.
    """
    df = df_bruto.copy()

    # Renomear colunas selecionadas
    df = df.rename(columns={
        col_datetime: 'data_hora_original',
        col_cliente: 'telefone_original'
    })

    if col_duracao and col_duracao in df_bruto.columns:
        df = df.rename(columns={col_duracao: 'duracao_original'})

    # --- PROCESSAR DATA/HORA ---
    st.write("ğŸ”„ Processando coluna de data/hora...")

    # Limpeza agressiva da coluna de data/hora
    df['data_hora_limpa'] = df['data_hora_original'].astype(str).str.strip()

    # Remover espaÃ§os mÃºltiplos, tabs, quebras de linha
    df['data_hora_limpa'] = df['data_hora_limpa'].str.replace(r'\s+', ' ', regex=True)

    # Remover caracteres invisÃ­veis comuns (zero-width space, etc)
    df['data_hora_limpa'] = df['data_hora_limpa'].str.replace(r'[\u200b\u200c\u200d\ufeff]', '', regex=True)

    # Remover espaÃ§os ao redor do T (se existir)
    df['data_hora_limpa'] = df['data_hora_limpa'].str.replace(r'\s*T\s*', 'T', regex=True)

    # Mostrar amostra dos dados limpos para debug
    st.write("**Amostra dos dados de data/hora apÃ³s limpeza:**")
    amostra_datas = df['data_hora_limpa'].head(10).tolist()
    for i, data in enumerate(amostra_datas, 1):
        st.text(f"{i}. '{data}' (tipo: {type(data).__name__}, len: {len(str(data))})")

    # Formatos de data/hora em ordem de prioridade
    # IMPORTANTE: Formatos ISO com T devem vir PRIMEIRO
    datetime_formats = [
        '%Y-%m-%dT%H:%M:%S',      # ISO 8601 com T (SEU FORMATO) - PRIORIDADE MÃXIMA
        '%Y-%m-%dT%H:%M:%S.%f',   # ISO com T e microsegundos
        '%Y-%m-%dT%H:%M',         # ISO com T sem segundos
        '%Y-%m-%d %H:%M:%S',      # ISO com espaÃ§o
        '%Y-%m-%d %H:%M:%S.%f',   # ISO com espaÃ§o e microsegundos
        '%Y-%m-%d %H:%M',         # ISO com espaÃ§o sem segundos
        '%d/%m/%Y %H:%M:%S',      # BR formato completo
        '%d/%m/%Y %H:%M',         # BR sem segundos
        '%d-%m-%Y %H:%M:%S',      # BR com traÃ§o
        '%d-%m-%Y %H:%M',         # BR com traÃ§o sem segundos
        '%Y/%m/%d %H:%M:%S',      # ISO com barra
        '%Y/%m/%d %H:%M',         # ISO com barra sem segundos
        '%d/%m/%Y',               # BR sÃ³ data
        '%Y-%m-%d',               # ISO sÃ³ data
        '%Y/%m/%d',               # ISO com barra sÃ³ data
    ]

    # Inicializar coluna de datetime
    df['datetime'] = pd.NaT
    total_rows = len(df)
    converted_count = 0

    st.write(f"\nğŸ“Š Total de registros a converter: **{total_rows:,}**")
    st.write("ğŸ” Tentando conversÃ£o com diferentes formatos...\n")

    # Tentar cada formato sequencialmente
    for fmt in datetime_formats:
        # Contar quantos ainda estÃ£o como NaT
        mask = df['datetime'].isna()
        pendentes = mask.sum()

        if pendentes == 0:
            st.success(f"âœ… Todos os {total_rows:,} registros foram convertidos!")
            break

        # Tentar converter apenas os que ainda sÃ£o NaT
        try:
            df.loc[mask, 'datetime'] = pd.to_datetime(
                df.loc[mask, 'data_hora_limpa'], 
                format=fmt, 
                errors='coerce'
            )

            # Contar quantos foram convertidos nesta iteraÃ§Ã£o
            newly_converted = (~df.loc[mask, 'datetime'].isna()).sum()

            if newly_converted > 0:
                converted_count += newly_converted
                percentual = (converted_count / total_rows) * 100
                st.info(f"   âœ“ Formato `{fmt}`: converteu **{newly_converted:,}** registros | "
                       f"Total: **{converted_count:,}/{total_rows:,}** ({percentual:.1f}%)")

        except Exception as e:
            st.warning(f"   âš ï¸ Erro ao tentar formato `{fmt}`: {str(e)}")
            continue

    # Ãšltima tentativa: inferÃªncia automÃ¡tica para os que restaram
    mask_final = df['datetime'].isna()
    pendentes_final = mask_final.sum()

    if pendentes_final > 0:
        st.warning(f"\nâš ï¸ Ainda hÃ¡ **{pendentes_final:,}** datas nÃ£o convertidas. "
                  f"Tentando inferÃªncia automÃ¡tica...")

        # Mostrar exemplos dos que falharam
        st.write("**Exemplos de datas que falharam:**")
        exemplos_falha = df.loc[mask_final, 'data_hora_limpa'].head(10).tolist()
        for i, data in enumerate(exemplos_falha, 1):
            st.text(f"{i}. '{data}'")

        try:
            # Tentar com dayfirst=True
            df.loc[mask_final, 'datetime'] = pd.to_datetime(
                df.loc[mask_final, 'data_hora_limpa'], 
                dayfirst=True, 
                errors='coerce'
            )

            final_converted = (~df.loc[mask_final, 'datetime'].isna()).sum()

            if final_converted > 0:
                converted_count += final_converted
                percentual = (converted_count / total_rows) * 100
                st.info(f"   âœ“ InferÃªncia automÃ¡tica: converteu **{final_converted:,}** registros | "
                       f"Total: **{converted_count:,}/{total_rows:,}** ({percentual:.1f}%)")

        except Exception as e:
            st.error(f"   âŒ Erro na inferÃªncia automÃ¡tica: {str(e)}")

    # Verificar quantos ainda sÃ£o NaT apÃ³s todas as tentativas
    registros_antes = len(df)
    nulos_finais = df['datetime'].isna().sum()

    if nulos_finais > 0:
        st.error(f"\nğŸš¨ **{nulos_finais:,}** registros ({(nulos_finais/total_rows)*100:.1f}%) "
                f"nÃ£o puderam ser convertidos e serÃ£o removidos.")

        # Mostrar mais exemplos dos que falharam
        st.write("**Ãšltimos 20 exemplos de datas que falharam completamente:**")
        mask_nulos = df['datetime'].isna()
        exemplos_nulos = df.loc[mask_nulos, ['data_hora_original', 'data_hora_limpa']].head(20)
        st.dataframe(exemplos_nulos)

        # Remover registros com datetime invÃ¡lido
        df = df.dropna(subset=['datetime'])

        st.warning(f"âš ï¸ Removidos {registros_antes - len(df):,} registros com data/hora invÃ¡lida.")
    else:
        st.success(f"\nğŸ‰ **100% dos registros convertidos com sucesso!** ({converted_count:,}/{total_rows:,})")

    if df.empty:
        st.error("ğŸš¨ Todos os registros foram removidos devido a datas/horas invÃ¡lidas. "
                "Verifique o formato da coluna de data/hora.")
        return None

    # Mostrar estatÃ­sticas da conversÃ£o
    st.write("\nğŸ“ˆ **EstatÃ­sticas da conversÃ£o:**")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Registros Originais", f"{total_rows:,}")
    with col2:
        st.metric("Convertidos com Sucesso", f"{converted_count:,}")
    with col3:
        taxa_sucesso = (converted_count / total_rows) * 100
        st.metric("Taxa de Sucesso", f"{taxa_sucesso:.1f}%")

    # Mostrar range de datas
    st.write(f"\nğŸ“… **PerÃ­odo dos dados:** {df['datetime'].min():%d/%m/%Y %H:%M:%S} "
            f"atÃ© {df['datetime'].max():%d/%m/%Y %H:%M:%S}")

    # --- PROCESSAR TELEFONE/CLIENTE ---
    st.write("\nğŸ”„ Processando coluna de cliente/telefone...")
    df['telefone'] = df['telefone_original'].astype(str).str.replace(r'[^\d]', '', regex=True)

    registros_antes = len(df)
    df = df[df['telefone'].str.len() >= 8]

    if len(df) < registros_antes:
        st.warning(f"âš ï¸ Removidos {registros_antes - len(df):,} registros com telefone invÃ¡lido "
                  f"(menos de 8 dÃ­gitos)")

    # --- PROCESSAR DURAÃ‡ÃƒO ---
    if 'duracao_original' in df.columns:
        st.write("ğŸ”„ Processando coluna de duraÃ§Ã£o...")
        df['duracao_segundos'] = df['duracao_original'].apply(converter_duracao_para_segundos)
    else:
        df['duracao_segundos'] = 0
        st.info("â„¹ï¸ Sem coluna de duraÃ§Ã£o - usando valor padrÃ£o 0")

    # Ordenar para anÃ¡lise
    df = df.sort_values(['telefone', 'datetime']).reset_index(drop=True)

    st.success(f"\nâœ… **{len(df):,}** ligaÃ§Ãµes processadas com sucesso!")

    return df


# --- 4. FUNÃ‡Ã•ES DE ANÃLISE (mantidas como no original) ---
def identificar_faixas_rechamada(df):
    """Identifica rechamadas em faixas de 0-24h, 24-48h, 48-72h."""
    rechamadas = {'0-24h': [], '24-48h': [], '48-72h': []}
    for telefone, grupo in df.groupby('telefone'):
        if len(grupo) < 2:
            continue
        grupo = grupo.sort_values('datetime')
        datas = grupo['datetime'].values
        duras = grupo['duracao_segundos'].values
        for i in range(1, len(datas)):
            diff_h = (datas[i] - datas[i-1]) / np.timedelta64(1, 'h')
            rec = {
                'telefone': telefone,
                'primeira_ligacao': datas[i-1],
                'segunda_ligacao': datas[i],
                'diferenca_horas': float(diff_h),
                'duracao_primeira_seg': duras[i-1],
                'duracao_segunda_seg': duras[i]
            }
            if diff_h <= 24:
                rechamadas['0-24h'].append(rec)
            elif 24 < diff_h <= 48:
                rechamadas['24-48h'].append(rec)
            elif 48 < diff_h <= 72:
                rechamadas['48-72h'].append(rec)
    return rechamadas

def faixas_ligacoes_e_reincidentes(df):
    """Calcula a contagem de ligaÃ§Ãµes por telefone e as faixas de reincidÃªncia."""
    contagem_por_telefone = df.groupby("telefone").size()
    faixas = {
        '1 ligaÃ§Ã£o': len(contagem_por_telefone[contagem_por_telefone == 1]),
        '2-5 ligaÃ§Ãµes': len(contagem_por_telefone[(contagem_por_telefone >= 2) & (contagem_por_telefone <= 5)]),
        '6-10 ligaÃ§Ãµes': len(contagem_por_telefone[(contagem_por_telefone >= 6) & (contagem_por_telefone <= 10)]),
        '11-20 ligaÃ§Ãµes': len(contagem_por_telefone[(contagem_por_telefone >= 11) & (contagem_por_telefone <= 20)]),
        '21-50 ligaÃ§Ãµes': len(contagem_por_telefone[(contagem_por_telefone >= 21) & (contagem_por_telefone <= 50)]),
        'Mais de 50 ligaÃ§Ãµes': len(contagem_por_telefone[contagem_por_telefone > 50])
    }
    telefones_ligaram_mais_de_uma_vez = len(contagem_por_telefone[contagem_por_telefone > 1])
    return faixas, telefones_ligaram_mais_de_uma_vez, contagem_por_telefone

def clientes_frequentes(df, N=50):
    """Identifica os N clientes que mais ligaram, com detalhes."""
    contagem = df.groupby('telefone').agg(
        total_ligacoes=('datetime', 'count'),
        primeira_ligacao=('datetime', 'min'),
        ultima_ligacao=('datetime', 'max'),
        duracao_total_seg=('duracao_segundos', 'sum'),
        duracao_media_seg=('duracao_segundos', 'mean')
    ).round(2)
    contagem['periodo_atividade_dias'] = (contagem['ultima_ligacao'] - contagem['primeira_ligacao']).dt.days
    contagem['frequencia_ligacoes_por_dia'] = contagem.apply(
        lambda x: x['total_ligacoes'] / max(1, x['periodo_atividade_dias']) if x['periodo_atividade_dias'] > 0 else x['total_ligacoes'], 
        axis=1
    ).round(2)
    contagem['duracao_total_min'] = (contagem['duracao_total_seg'] / 60).round(2)
    contagem['duracao_media_min'] = (contagem['duracao_media_seg'] / 60).round(2)
    return contagem.sort_values('total_ligacoes', ascending=False).head(N)

def calcular_impacto_financeiro(rechamadas, valor_ligacao=VALOR_LIGACAO):
    """Calcula o impacto financeiro das rechamadas."""
    impacto_por_faixa = {k: len(v) * valor_ligacao for k, v in rechamadas.items()}
    total_religacoes = sum(len(v) for v in rechamadas.values())
    return {
        'total_religacoes': total_religacoes,
        'impacto_total': total_religacoes * valor_ligacao,
        'valor_por_ligacao': valor_ligacao,
        'impacto_por_faixa': impacto_por_faixa
    }

def gerar_consolidado(df, rechamadas, clientes_frequentes_df, faixas_ligacoes, telefones_reincidentes, impacto_financeiro):
    """Gera um dicionÃ¡rio consolidado com todas as mÃ©tricas para relatÃ³rios."""
    dias_pt = {
        'Monday': 'Segunda', 'Tuesday': 'TerÃ§a', 'Wednesday': 'Quarta',
        'Thursday': 'Quinta', 'Friday': 'Sexta', 'Saturday': 'SÃ¡bado', 'Sunday': 'Domingo'
    }
    stats = {
        'total_ligacoes': len(df),
        'clientes_unicos': df['telefone'].nunique(),
        'media_ligacoes_por_cliente': round(len(df) / df['telefone'].nunique(), 2),
        'periodo_analise': f"{df['datetime'].min():%d/%m/%Y} a {df['datetime'].max():%d/%m/%Y}",
        'duracao_total_horas': round(df['duracao_segundos'].sum() / 3600, 2),
        'duracao_media_minutos': round(df['duracao_segundos'].mean() / 60, 2)
    }
    df['dia_semana'] = df['datetime'].dt.day_name().map(dias_pt)
    ligacoes_por_dia = df['dia_semana'].value_counts().to_dict()
    df['hora'] = df['datetime'].dt.hour
    horarios_pico = df['hora'].value_counts().head(5).to_dict()
    religacoes_resumo = {
        faixa: {
            'quantidade': len(dados),
            'clientes_unicos': len(set(item['telefone'] for item in dados)) if dados else 0,
            'tempo_medio_horas': float(np.mean([item['diferenca_horas'] for item in dados]) if dados else 0),
            'impacto_financeiro': impacto_financeiro['impacto_por_faixa'][faixa]
        } for faixa, dados in rechamadas.items()
    }
    top_10_clientes = clientes_frequentes_df.head(10)[['total_ligacoes', 'frequencia_ligacoes_por_dia', 'duracao_total_min']].to_dict(orient='index')
    return {
        'estatisticas_gerais': stats,
        'ligacoes_por_dia': ligacoes_por_dia,
        'horarios_pico': {f'{int(k)}h': int(v) for k, v in horarios_pico.items()},
        'religacoes': religacoes_resumo,
        'top_clientes': top_10_clientes,
        'faixas_ligacoes': faixas_ligacoes,
        'telefones_reincidentes': telefones_reincidentes,
        'impacto_financeiro': impacto_financeiro
    }

# --- 5. FUNÃ‡Ã•ES DE VISUALIZAÃ‡ÃƒO (mantidas como no original) ---
def create_dashboard_plots(consolidado, reincidentes_serie, min_ligacoes_graf):
    """Cria os grÃ¡ficos individuais para o dashboard Streamlit."""
    plt.style.use('seaborn-v0_8-whitegrid')
    plots = {}

    # 1. LigaÃ§Ãµes por Dia da Semana
    fig_dia, ax_dia = plt.subplots(figsize=(8, 4))
    dias = list(consolidado['ligacoes_por_dia'].keys())
    valores_dia = list(consolidado['ligacoes_por_dia'].values())
    bars_dia = ax_dia.bar(dias, valores_dia, color='skyblue', edgecolor='navy')
    ax_dia.set_title('ğŸ“… LigaÃ§Ãµes por Dia da Semana', fontsize=12)
    ax_dia.tick_params(axis='x', rotation=45, labelsize=10)
    ax_dia.tick_params(axis='y', labelsize=10)
    for bar in bars_dia:
        ax_dia.text(bar.get_x() + bar.get_width()/2., bar.get_height(), 
                   f'{int(bar.get_height()):,}', ha='center', va='bottom', fontsize=8)
    plt.tight_layout()
    plots['ligacoes_por_dia'] = fig_dia

    # 2. HorÃ¡rios de Pico
    fig_hora, ax_hora = plt.subplots(figsize=(8, 4))
    horas = list(consolidado['horarios_pico'].keys())
    valores_hora = list(consolidado['horarios_pico'].values())
    bars_hora = ax_hora.bar(horas, valores_hora, color='lightgreen', edgecolor='darkgreen')
    ax_hora.set_title('ğŸ• Top 5 HorÃ¡rios de Pico', fontsize=12)
    ax_hora.tick_params(axis='x', labelsize=10)
    ax_hora.tick_params(axis='y', labelsize=10)
    for bar in bars_hora:
        ax_hora.text(bar.get_x() + bar.get_width()/2., bar.get_height(), 
                    f'{int(bar.get_height()):,}', ha='center', va='bottom', fontsize=8)
    plt.tight_layout()
    plots['horarios_pico'] = fig_hora

    # 3. Faixas de LigaÃ§Ãµes
    fig_faixas, ax_faixas = plt.subplots(figsize=(8, 8))
    faixas_labels = [k for k, v in consolidado['faixas_ligacoes'].items() if v > 0]
    faixas_sizes = [v for v in consolidado['faixas_ligacoes'].values() if v > 0]
    if faixas_sizes:
        colors = plt.cm.Pastel1(np.linspace(0, 1, len(faixas_sizes)))
        ax_faixas.pie(faixas_sizes, labels=faixas_labels, autopct='%1.1f%%', 
                     colors=colors, startangle=90, textprops={'fontsize': 10})
        ax_faixas.set_title('ğŸ“Š DistribuiÃ§Ã£o por Faixas de LigaÃ§Ãµes', fontsize=12)
    else:
        ax_faixas.text(0.5, 0.5, 'Nenhuma faixa de ligaÃ§Ã£o para exibir', 
                      horizontalalignment='center', verticalalignment='center', 
                      transform=ax_faixas.transAxes, fontsize=10)
        ax_faixas.axis('off')
    plt.tight_layout()
    plots['faixas_ligacoes'] = fig_faixas

    # 4. Rechamadas por PerÃ­odo
    fig_relig, ax_relig = plt.subplots(figsize=(8, 4))
    periodos = ['0-24h', '24-48h', '48-72h']
    qtd_religacoes = [consolidado['religacoes'][p]['quantidade'] for p in periodos]
    bars_relig = ax_relig.bar(periodos, qtd_religacoes, color=['red', 'orange', 'gold'], edgecolor='black')
    ax_relig.set_title('ğŸ“ Rechamadas por PerÃ­odo', fontsize=12)
    ax_relig.tick_params(axis='x', labelsize=10)
    ax_relig.tick_params(axis='y', labelsize=10)
    for bar in bars_relig:
        ax_relig.text(bar.get_x() + bar.get_width()/2., bar.get_height(), 
                     f'{int(bar.get_height()):,}', ha='center', va='bottom', fontsize=8)
    plt.tight_layout()
    plots['rechamadas_por_periodo'] = fig_relig

    # 5. Histograma de ReincidÃªncia
    fig_hist, ax_hist = plt.subplots(figsize=(8, 4))
    if not reincidentes_serie.empty:
        sns.histplot(reincidentes_serie, bins=range(min_ligacoes_graf, reincidentes_serie.max() + 2), 
                    kde=False, ax=ax_hist, color='darkorchid')
        ax_hist.set_title(f'ğŸ“‰ ReincidÃªncia (Telefones com â‰¥{min_ligacoes_graf} LigaÃ§Ãµes)', fontsize=12)
        ax_hist.set_xlabel('NÃºmero de LigaÃ§Ãµes', fontsize=10)
        ax_hist.set_ylabel('Quantidade de Telefones', fontsize=10)
        ax_hist.tick_params(axis='x', labelsize=9)
        ax_hist.tick_params(axis='y', labelsize=9)
    else:
        ax_hist.text(0.5, 0.5, 'Nenhum telefone com â‰¥2 ligaÃ§Ãµes', 
                    horizontalalignment='center', verticalalignment='center', 
                    transform=ax_hist.transAxes, fontsize=10)
        ax_hist.axis('off')
    plt.tight_layout()
    plots['hist_reincidencia'] = fig_hist

    # 6. Top 10 Clientes
    fig_top_clientes, ax_top_clientes = plt.subplots(figsize=(8, 4))
    top_clientes_df = pd.DataFrame(consolidado['top_clientes']).T
    if not top_clientes_df.empty:
        bars_top = ax_top_clientes.bar(top_clientes_df.index.astype(str), 
                                       top_clientes_df['total_ligacoes'], 
                                       color='teal', edgecolor='black')
        ax_top_clientes.set_title('ğŸ† Top 10 Clientes que Mais Ligaram', fontsize=12)
        ax_top_clientes.set_xlabel('Telefone', fontsize=10)
        ax_top_clientes.set_ylabel('Total de LigaÃ§Ãµes', fontsize=10)
        ax_top_clientes.tick_params(axis='x', labelsize=9, rotation=45)
        ax_top_clientes.set_xticklabels(top_clientes_df.index.astype(str), rotation=45, ha='right', fontsize=9)
        ax_top_clientes.tick_params(axis='y', labelsize=9)
        for bar in bars_top:
            ax_top_clientes.text(bar.get_x() + bar.get_width()/2., bar.get_height(), 
                                f'{int(bar.get_height())}', ha='center', va='bottom', fontsize=7)
    else:
        ax_top_clientes.text(0.5, 0.5, 'Nenhum cliente frequente encontrado', 
                           horizontalalignment='center', verticalalignment='center', 
                           transform=ax_top_clientes.transAxes, fontsize=10)
        ax_top_clientes.axis('off')
    plt.tight_layout()
    plots['top_clientes'] = fig_top_clientes

    return plots

def to_excel_buffer(df, rechamadas_detalhe, clientes_frequentes_todos, consolidado, 
                   faixas_ligacoes, contagem_por_telefone_bruta, reincidentes_serie_filtrada):
    """Salva todos os resultados em Excel."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        # Consolidado Geral
        stats = consolidado['estatisticas_gerais']
        impacto = consolidado['impacto_financeiro']
        consolidado_data = [
            ['Total de LigaÃ§Ãµes', stats['total_ligacoes']],
            ['Clientes Ãšnicos', stats['clientes_unicos']],
            ['NÃºmeros que ligaram mais de uma vez', consolidado['telefones_reincidentes']],
            ['MÃ©dia LigaÃ§Ãµes/Cliente', stats['media_ligacoes_por_cliente']],
            ['PerÃ­odo de AnÃ¡lise', stats['periodo_analise']],
            ['DuraÃ§Ã£o Total (horas)', stats['duracao_total_horas']],
            ['DuraÃ§Ã£o MÃ©dia por LigaÃ§Ã£o (min)', stats['duracao_media_minutos']],
            ['', ''],
            ['IMPACTO FINANCEIRO', ''],
            ['Total de Rechamadas', impacto['total_religacoes']],
            ['Custo por LigaÃ§Ã£o', f"R$ {impacto['valor_por_ligacao']:.2f}"],
            ['Impacto Total Estimado', f"R$ {impacto['impacto_total']:,.2f}"]
        ]
        for periodo, valor in impacto['impacto_por_faixa'].items():
            consolidado_data.append([f'Impacto {periodo}', f"R$ {valor:,.2f}"])
        pd.DataFrame(consolidado_data, columns=['MÃ©trica', 'Valor']).to_excel(writer, sheet_name='Consolidado', index=False)

        # Outras abas
        pd.DataFrame(list(consolidado['ligacoes_por_dia'].items()), 
                    columns=['Dia da Semana', 'Quantidade']).to_excel(writer, sheet_name='Ligacoes_por_Dia', index=False)

        pd.DataFrame(list(consolidado['horarios_pico'].items()), 
                    columns=['HorÃ¡rio (h)', 'Quantidade']).to_excel(writer, sheet_name='Ligacoes_por_Hora', index=False)

        pd.DataFrame(list(faixas_ligacoes.items()), 
                    columns=['Faixa de LigaÃ§Ãµes', 'Quantidade de Telefones']).to_excel(writer, sheet_name='Faixas_Ligacoes', index=False)

        # Rechamadas
        rechamadas_resumo_data = []
        for periodo, dados in consolidado['religacoes'].items():
            rechamadas_resumo_data.append([
                periodo,
                dados['quantidade'],
                dados['clientes_unicos'],
                f"{dados['tempo_medio_horas']:.1f}h",
                f"R$ {dados['impacto_financeiro']:,.2f}"
            ])
        pd.DataFrame(rechamadas_resumo_data, 
                    columns=['PerÃ­odo', 'Qtd. Rechamadas', 'Clientes Ãšnicos', 'Tempo MÃ©dio', 'Impacto Financeiro']
                    ).to_excel(writer, sheet_name='Rechamadas_Resumo', index=False)

        for periodo, dados in rechamadas_detalhe.items():
            if dados:
                pd.DataFrame(dados).to_excel(writer, sheet_name=f'Rechamadas_{periodo}', index=False)

        # Top clientes
        top_10_clientes_df = pd.DataFrame(consolidado['top_clientes']).T.reset_index()
        top_10_clientes_df.columns = ['Telefone', 'Total LigaÃ§Ãµes', 'FrequÃªncia/Dia', 'DuraÃ§Ã£o Total (min)']
        top_10_clientes_df.to_excel(writer, sheet_name='Top_10_Clientes', index=False)

        # ReincidÃªncia
        if not reincidentes_serie_filtrada.empty:
            reincidentes_serie_filtrada.rename("Quantidade_Ligacoes").to_frame().to_excel(
                writer, sheet_name='Reincidencia_Telefones', index=True)

        # Dados detalhados
        clientes_frequentes_todos.to_excel(writer, sheet_name='Dados_Clientes_Detalhados', index=True)
        contagem_por_telefone_bruta.rename("Quantidade_Ligacoes").to_frame().to_excel(
            writer, sheet_name='Contagem_Bruta_Telefones', index=True)

    output.seek(0)
    return output

# --- 6. APLICAÃ‡ÃƒO STREAMLIT PRINCIPAL ---
def streamlit_app():
    st.set_page_config(layout="wide", page_title="AnÃ¡lise de Rechamadas Call Center")

    st.title("ğŸ“ AnÃ¡lise de Rechamadas do Call Center")
    st.markdown("FaÃ§a o upload do seu arquivo de dados (CSV ou Excel) para analisar padrÃµes de rechamadas.")

    # Upload do arquivo
    uploaded_file = st.file_uploader("Escolha um arquivo CSV ou Excel", type=["csv", "xlsx", "xls"])

    if uploaded_file is not None:
        # Carregar arquivo inicial
        df_bruto, error_message = carregar_arquivo_inicial(uploaded_file)

        if error_message:
            st.error(error_message)
            st.stop()

        if df_bruto is not None and not df_bruto.empty:
            st.markdown("---")
            st.subheader("ğŸ“‹ SeleÃ§Ã£o de Colunas")

            # Mostrar amostra dos dados
            with st.expander("ğŸ‘ï¸ Visualizar amostra dos dados carregados"):
                st.dataframe(df_bruto.head(10))

            # Detectar sugestÃµes automÃ¡ticas
            sugestao_datetime = detectar_coluna_sugerida(df_bruto, 'datetime')
            sugestao_telefone = detectar_coluna_sugerida(df_bruto, 'telefone')
            sugestao_duracao = detectar_coluna_sugerida(df_bruto, 'duracao')

            colunas_disponiveis = list(df_bruto.columns)

            # Interface de seleÃ§Ã£o de colunas
            col1, col2, col3 = st.columns(3)

            with col1:
                st.markdown("**ğŸ• Coluna de Data/Hora** *(obrigatÃ³ria)*")
                idx_datetime = colunas_disponiveis.index(sugestao_datetime) if sugestao_datetime else 0
                col_datetime = st.selectbox(
                    "Selecione a coluna que contÃ©m data/hora:",
                    colunas_disponiveis,
                    index=idx_datetime,
                    key='datetime_col'
                )
                if sugestao_datetime:
                    st.caption(f"âœ… SugestÃ£o automÃ¡tica: {sugestao_datetime}")

            with col2:
                st.markdown("**ğŸ“± Coluna de Cliente/Telefone** *(obrigatÃ³ria)*")
                idx_telefone = colunas_disponiveis.index(sugestao_telefone) if sugestao_telefone else 0
                col_cliente = st.selectbox(
                    "Selecione a coluna que identifica o cliente:",
                    colunas_disponiveis,
                    index=idx_telefone,
                    key='cliente_col'
                )
                if sugestao_telefone:
                    st.caption(f"âœ… SugestÃ£o automÃ¡tica: {sugestao_telefone}")

            with col3:
                st.markdown("**â±ï¸ Coluna de DuraÃ§Ã£o** *(opcional)*")
                opcoes_duracao = ['Nenhuma'] + colunas_disponiveis
                idx_duracao = opcoes_duracao.index(sugestao_duracao) if sugestao_duracao else 0
                col_duracao = st.selectbox(
                    "Selecione a coluna de duraÃ§Ã£o (se houver):",
                    opcoes_duracao,
                    index=idx_duracao,
                    key='duracao_col'
                )
                if sugestao_duracao:
                    st.caption(f"âœ… SugestÃ£o automÃ¡tica: {sugestao_duracao}")

            # ValidaÃ§Ã£o
            if col_datetime == col_cliente:
                st.error("âŒ As colunas de data/hora e cliente nÃ£o podem ser iguais!")
                st.stop()

            # BotÃ£o para processar
            if st.button("ğŸš€ Processar Dados", type="primary"):
                col_duracao_final = None if col_duracao == 'Nenhuma' else col_duracao

                # Processar dados
                df_processado = processar_dados(df_bruto, col_datetime, col_cliente, col_duracao_final)

                if df_processado is None or df_processado.empty:
                    st.error("NÃ£o foi possÃ­vel processar os dados. Verifique as colunas selecionadas.")
                    st.stop()

                # Armazenar no session_state para persistir
                st.session_state['df_processado'] = df_processado
                st.session_state['processamento_concluido'] = True

            # Se jÃ¡ processou, mostrar anÃ¡lises
            if st.session_state.get('processamento_concluido', False):
                df = st.session_state['df_processado']

                st.markdown("---")
                st.subheader("ğŸ“Š Executando AnÃ¡lises...")

                # AnÃ¡lises
                rechamadas_detalhe = identificar_faixas_rechamada(df)
                faixas_ligacoes, telefones_reincidentes, contagem_por_telefone_bruta = faixas_ligacoes_e_reincidentes(df)
                clientes_frequentes_todos = clientes_frequentes(df, N=df['telefone'].nunique())
                impacto_financeiro = calcular_impacto_financeiro(rechamadas_detalhe)
                consolidado = gerar_consolidado(df, rechamadas_detalhe, clientes_frequentes_todos, 
                                               faixas_ligacoes, telefones_reincidentes, impacto_financeiro)
                reincidentes_serie_filtrada = contagem_por_telefone_bruta[contagem_por_telefone_bruta >= MIN_LIGACOES_GRAF]

                st.success("âœ… AnÃ¡lises concluÃ­das!")

                # SumÃ¡rio Executivo
                st.markdown("---")
                st.header("ğŸ“ˆ SumÃ¡rio Executivo")

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Total de LigaÃ§Ãµes", f"{consolidado['estatisticas_gerais']['total_ligacoes']:,}")
                    st.metric("Clientes Ãšnicos", f"{consolidado['estatisticas_gerais']['clientes_unicos']:,}")
                with col2:
                    st.metric("NÃºmeros com >1 LigaÃ§Ã£o", f"{consolidado['telefones_reincidentes']:,}")
                    st.metric("MÃ©dia LigaÃ§Ãµes/Cliente", f"{consolidado['estatisticas_gerais']['media_ligacoes_por_cliente']:.2f}")
                with col3:
                    st.metric("DuraÃ§Ã£o Total (horas)", f"{consolidado['estatisticas_gerais']['duracao_total_horas']:,}h")
                    st.metric("DuraÃ§Ã£o MÃ©dia/LigaÃ§Ã£o (min)", f"{consolidado['estatisticas_gerais']['duracao_media_minutos']:.1f} min")

                st.subheader("ğŸ’° Impacto Financeiro das Rechamadas")
                st.metric("Impacto Total Estimado", f"R$ {consolidado['impacto_financeiro']['impacto_total']:,.2f}")
                st.dataframe(pd.DataFrame(consolidado['impacto_financeiro']['impacto_por_faixa'].items(), 
                                        columns=['PerÃ­odo', 'Impacto Financeiro (R$)']).set_index('PerÃ­odo'))

                # VisualizaÃ§Ãµes
                st.markdown("---")
                st.header("ğŸ“Š VisualizaÃ§Ãµes Detalhadas")

                dashboard_plots = create_dashboard_plots(consolidado, reincidentes_serie_filtrada, MIN_LIGACOES_GRAF)

                st.subheader("ğŸ“… LigaÃ§Ãµes por Dia da Semana")
                st.pyplot(dashboard_plots['ligacoes_por_dia'])

                st.subheader("ğŸ• Top 5 HorÃ¡rios de Pico")
                st.pyplot(dashboard_plots['horarios_pico'])

                st.subheader("ğŸ“Š DistribuiÃ§Ã£o por Faixas de LigaÃ§Ãµes")
                st.pyplot(dashboard_plots['faixas_ligacoes'])

                st.subheader("ğŸ“ Rechamadas por PerÃ­odo")
                st.pyplot(dashboard_plots['rechamadas_por_periodo'])

                st.subheader(f"ğŸ“‰ ReincidÃªncia (Telefones com â‰¥{MIN_LIGACOES_GRAF} LigaÃ§Ãµes)")
                st.pyplot(dashboard_plots['hist_reincidencia'])

                st.subheader("ğŸ† Top 10 Clientes que Mais Ligaram")
                st.pyplot(dashboard_plots['top_clientes'])

                # Download
                st.markdown("---")
                st.header("ğŸ’¾ Download dos Resultados")

                excel_buffer = to_excel_buffer(df, rechamadas_detalhe, clientes_frequentes_todos, 
                                              consolidado, faixas_ligacoes, contagem_por_telefone_bruta, 
                                              reincidentes_serie_filtrada)
                st.download_button(
                    label="ğŸ“¥ Baixar RelatÃ³rio Completo em Excel",
                    data=excel_buffer,
                    file_name=f"analise_callcenter_completa_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

if __name__ == "__main__":
    streamlit_app()
